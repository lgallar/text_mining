{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GOfHlQN8SHbQ"
   },
   "source": [
    "# Model with pretrained embeddings\n",
    "    - Glove embeddings. Vectors of 300 dim.\n",
    "    - Model: Basic LSTM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e1PzSwhxS_Vw"
   },
   "outputs": [],
   "source": [
    "# Configure to use tensorboard in colab\n",
    "\n",
    "#CPU\n",
    "#!pip install -q tensorflow==2.0.0-alpha0\n",
    "\n",
    "#GPU\n",
    "!pip install -q tensorflow-gpu==2.0.0-alpha0\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard.notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1yGHjaY_SHbS"
   },
   "outputs": [],
   "source": [
    "# Header\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print('Tensorflow version: ', tf.__version__)\n",
    "import time\n",
    "\n",
    "#Show images\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 10) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0ix3gXeMSHbX"
   },
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mwAFg-mMTLHB"
   },
   "outputs": [],
   "source": [
    "# link drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BDGTrK38SHbX"
   },
   "outputs": [],
   "source": [
    "# Import train and test data\n",
    "save_path= './gdrive/My Drive/text_mining'\n",
    "\n",
    "X_train = np.load(os.path.join(save_path, 'X_train.npy'))\n",
    "y_train = np.load(os.path.join(save_path, 'y_train.npy'))\n",
    "X_test  = np.load(os.path.join(save_path, 'X_test.npy'))\n",
    "y_test  = np.load(os.path.join(save_path, 'y_test.npy'))\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kpjtXdCaSHba"
   },
   "source": [
    "## Load embeddings and join with the current dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GyNFVVnFSjg0"
   },
   "outputs": [],
   "source": [
    "# download embedings\n",
    "! wget https://s3-eu-west-1.amazonaws.com/text-mining-course/glove.6B.100d.txt.zip\n",
    "! unzip glove.6B.100d.txt.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v5GPfsMTSHbb"
   },
   "outputs": [],
   "source": [
    "#Load embeddings\n",
    "import pandas as pd\n",
    "import csv\n",
    "import pickle\n",
    "\n",
    "# Load worddict\n",
    "with open(os.path.join(save_path, 'worddict.pickle'), 'rb') as pfile:\n",
    "    worddict = pickle.load(pfile)\n",
    "\n",
    "embed_dim = 100\n",
    "df_glove = pd.read_csv(\"glove.6B.100d.txt\", index_col=0 ,sep=' ',\n",
    "                   header = None, quoting=csv.QUOTE_NONE, encoding='utf-8')\n",
    "\n",
    "#Merge with the dictionary of the current texts: Inner join, only words in the corpus and in glove.\n",
    "df_glove = df_glove.merge(pd.DataFrame.from_dict(worddict, orient='index'), left_index=True, right_index=True)\n",
    "print('Merged words: ', df_glove.shape[0])\n",
    "\n",
    "#Create dictionary: word_number_id --> [glove vector associated]\n",
    "glove={}\n",
    "for i,r in df_glove[:].iterrows():\n",
    "    glove[int(r[0])] = [r[j] for j in range(1,embed_dim+1)]\n",
    "print('Dictionary length: ', len(glove))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j1GUqVHoSHbe"
   },
   "source": [
    "## Prepare sequences to model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IlJBH73VSHbf"
   },
   "outputs": [],
   "source": [
    "#Create embeddings 3D tensors\n",
    "max_len = 100\n",
    "\n",
    "def embedd(x):\n",
    "    r = np.zeros((max_len, embed_dim))\n",
    "    pos = max_len-1\n",
    "    for i in range(len(x),0,-1):\n",
    "        found = True\n",
    "        try:\n",
    "            v = np.array([glove[x[i-1]]])\n",
    "        except:\n",
    "            found = False\n",
    "        if found and pos>=0:\n",
    "            r[pos,:] = v \n",
    "            pos += -1\n",
    "    return r\n",
    "        \n",
    "X_train = np.array([embedd(s) for s in X_train], dtype=np.float32)\n",
    "print('Train shape:', X_train.shape)\n",
    "\n",
    "X_test = np.array([embedd(s) for s in X_test], dtype=np.float32)\n",
    "print('Test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "yzPxYt-HSHbj"
   },
   "source": [
    "# Save data in HDF5 to use with a batch generator\n",
    "\n",
    "```\n",
    "import h5py\n",
    "with h5py.File(data_path + 'sentiment_glove_data.h5') as hdf5_f:\n",
    "    hdf5_f.create_dataset('X_train', data=np.array(X_train))\n",
    "    hdf5_f.create_dataset('y_train', data=np.array(y_train))\n",
    "    hdf5_f.create_dataset('X_test' , data=np.array(X_test ))\n",
    "    hdf5_f.create_dataset('y_test' , data=np.array(y_test ))\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EjhnsZlJSHbj"
   },
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BxQON5WfSHbm"
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "num_hidden_rnn = 128 #Num of neurons in the Recurent network \n",
    "\n",
    "\n",
    "print('Build model 1 - Basic model...')\n",
    "\n",
    "# LAYER 1: inputs\n",
    "seq_prev_input = tf.keras.layers.Input(shape=(max_len, embed_dim), dtype='float32',) \n",
    "\n",
    "# LAYER 2: Create embedings\n",
    "#embeds = tf.keras.layers.Embedding(max_features, dim_embedings, input_length=max_len)(seq_prev_input)\n",
    "\n",
    "# LAYERS 3: RNN - forwards LSTM with dropout\n",
    "forward = tf.keras.layers.LSTM(num_hidden_rnn, return_sequences=True,\n",
    "                 dropout=0.3, recurrent_dropout=0.3, name='Forward1')(seq_prev_input)\n",
    "rnn_out = tf.keras.layers.LSTM(num_hidden_rnn, return_sequences=False,\n",
    "                 dropout=0.3, recurrent_dropout=0.3, name='Forward2')(forward)\n",
    "\n",
    "\n",
    "# LAYER 4: Dense layer to outputs - softmax activation\n",
    "output = tf.keras.layers.Dense(2, activation='softmax')(rnn_out)\n",
    "\n",
    "# Model Architecture defined\n",
    "model_1 = tf.keras.models.Model(inputs=seq_prev_input, outputs=output)\n",
    "model_1.summary()\n",
    "\n",
    "# Compile model and select optimizer\n",
    "model_1.compile(loss='sparse_categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SkI5AiCNSHbq"
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "batch_size = 128\n",
    "\n",
    "print(\"Train...\")\n",
    "tbCallBack = tf.keras.callbacks.TensorBoard(log_dir='./tensorboard/sentiment/PretrainedEmbeds')\n",
    "history = model_1.fit(X_train, y_train, batch_size=batch_size, epochs=20,\n",
    "                      validation_data=(X_test, y_test), callbacks=[tbCallBack])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GkrmQvPES7V9"
   },
   "outputs": [],
   "source": [
    "# Start tensorboard\n",
    "%tensorboard --logdir ./tensorboard/sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H3wLmZ8USHbt"
   },
   "outputs": [],
   "source": [
    "#Plot graphs in the notebook output\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k6JA9I55SHbw"
   },
   "source": [
    "## Validate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z_o5vyFYSHbx"
   },
   "outputs": [],
   "source": [
    "# Score and obtain probabilities\n",
    "pred_test = model_1.predict(X_test)\n",
    "print(pred_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "egUHrnr5SHb0"
   },
   "outputs": [],
   "source": [
    "#Import metrics\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "\n",
    "#Calculate accuracy with sklearn\n",
    "print('Accuracy: ',accuracy_score(y_test, [1 if p>0.5 else 0 for p in pred_test[:,1]]))\n",
    "\n",
    "#Calculate ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, pred_test[:,1])\n",
    "print('AUC: ', auc(fpr, tpr) ) \n",
    "\n",
    "#Plot ROC curve\n",
    "plt.plot(fpr, tpr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "McfSSFxKSHb4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z_jkaAgOSHb6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "05_Model5_RNN with_pretrained_embeddings.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
